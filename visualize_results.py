#!/usr/bin/env python3
"""
VieCut Test Results Visualization Script

This script reads the CSV file generated by build_and_test.sh
and creates performance visualization plots.

Usage:
    python3 visualize_results.py test_results_YYYYMMDD_HHMMSS.csv
"""

import sys
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib
matplotlib.use('Agg')  # Use non-interactive backend
import numpy as np
from pathlib import Path

def plot_sequential_comparison(df, output_dir):
    """Plot sequential algorithms comparison"""
    # Filter sequential algorithms (thread count = 1, base variant)
    seq_df = df[(df['Threads'] == 1) & (df['Variant'] == 'base')]

    # Get unique sequential algorithms
    seq_algos = ['ks', 'noi', 'matula', 'vc', 'pr', 'cactus']
    seq_data = seq_df[seq_df['Algorithm'].isin(seq_algos)]

    if seq_data.empty:
        print("⚠️  No sequential data found")
        return

    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))

    # Time comparison
    algorithms = seq_data['Algorithm'].values
    times = seq_data['Time'].values
    colors = plt.cm.Set3(range(len(algorithms)))

    bars1 = ax1.bar(algorithms, times, color=colors)
    ax1.set_ylabel('Time (seconds)', fontsize=12)
    ax1.set_xlabel('Algorithm', fontsize=12)
    ax1.set_title('Sequential Algorithms - Execution Time', fontsize=14, fontweight='bold')
    ax1.grid(axis='y', alpha=0.3)

    # Add value labels on bars
    for bar in bars1:
        height = bar.get_height()
        ax1.text(bar.get_x() + bar.get_width()/2., height,
                f'{height:.3f}s',
                ha='center', va='bottom', fontsize=9)

    # Speedup comparison (relative to slowest)
    slowest_time = times.max()
    speedups = slowest_time / times

    bars2 = ax2.bar(algorithms, speedups, color=colors)
    ax2.set_ylabel('Speedup (relative to slowest)', fontsize=12)
    ax2.set_xlabel('Algorithm', fontsize=12)
    ax2.set_title('Sequential Algorithms - Relative Speedup', fontsize=14, fontweight='bold')
    ax2.axhline(y=1.0, color='red', linestyle='--', alpha=0.5, label='Baseline')
    ax2.grid(axis='y', alpha=0.3)
    ax2.legend()

    # Add value labels
    for bar in bars2:
        height = bar.get_height()
        ax2.text(bar.get_x() + bar.get_width()/2., height,
                f'{height:.2f}x',
                ha='center', va='bottom', fontsize=9)

    plt.tight_layout()
    output_file = output_dir / 'sequential_comparison.png'
    plt.savefig(output_file, dpi=300, bbox_inches='tight')
    print(f"✓ Sequential comparison saved to: {output_file}")
    plt.close()


def plot_parallel_speedup(df, output_dir):
    """Plot parallel speedup and efficiency"""
    # Filter parallel algorithms
    par_algos = ['inexact', 'exact', 'cactus']
    par_df = df[df['Algorithm'].str.contains('par', na=False)]

    if par_df.empty:
        print("⚠️  No parallel data found")
        return

    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))

    # Speedup plot
    for algo in par_algos:
        algo_data = par_df[par_df['Algorithm'].str.contains(algo)]
        if not algo_data.empty:
            threads = algo_data['Threads'].values
            speedups = algo_data['Speedup'].values
            ax1.plot(threads, speedups, marker='o', linewidth=2, markersize=8, label=algo)

    # Ideal speedup line
    max_threads = par_df['Threads'].max()
    ax1.plot([1, max_threads], [1, max_threads], 'k--', alpha=0.5, label='Ideal (linear)')

    ax1.set_xlabel('Number of Threads', fontsize=12)
    ax1.set_ylabel('Speedup', fontsize=12)
    ax1.set_title('Parallel Speedup vs Thread Count', fontsize=14, fontweight='bold')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    ax1.set_xticks(sorted(par_df['Threads'].unique()))

    # Efficiency plot
    for algo in par_algos:
        algo_data = par_df[par_df['Algorithm'].str.contains(algo)]
        if not algo_data.empty:
            threads = algo_data['Threads'].values
            efficiency = algo_data['Efficiency'].values
            ax2.plot(threads, efficiency, marker='s', linewidth=2, markersize=8, label=algo)

    # 100% efficiency line
    ax2.axhline(y=100, color='k', linestyle='--', alpha=0.5, label='100% Efficiency')

    ax2.set_xlabel('Number of Threads', fontsize=12)
    ax2.set_ylabel('Efficiency (%)', fontsize=12)
    ax2.set_title('Parallel Efficiency vs Thread Count', fontsize=14, fontweight='bold')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    ax2.set_xticks(sorted(par_df['Threads'].unique()))
    ax2.set_ylim(0, 120)

    plt.tight_layout()
    output_file = output_dir / 'parallel_speedup.png'
    plt.savefig(output_file, dpi=300, bbox_inches='tight')
    print(f"✓ Parallel speedup saved to: {output_file}")
    plt.close()


def plot_strong_scaling(df, output_dir):
    """Plot strong scaling analysis"""
    par_algos = ['inexact', 'exact', 'cactus']
    par_df = df[df['Algorithm'].str.contains('par', na=False)]

    if par_df.empty:
        print("⚠️  No parallel data for strong scaling")
        return

    fig, ax = plt.subplots(figsize=(10, 6))

    for algo in par_algos:
        algo_data = par_df[par_df['Algorithm'].str.contains(algo)].sort_values('Threads')
        if not algo_data.empty and len(algo_data) > 1:
            threads = algo_data['Threads'].values
            times = algo_data['Time'].values

            # Calculate speedup relative to 1-thread
            baseline_time = algo_data[algo_data['Threads'] == 1]['Time'].values
            if len(baseline_time) > 0:
                speedup = baseline_time[0] / times
                ax.plot(threads, speedup, marker='o', linewidth=2, markersize=8, label=algo)

    # Ideal speedup
    max_threads = par_df['Threads'].max()
    ax.plot([1, max_threads], [1, max_threads], 'k--', alpha=0.5, linewidth=2, label='Ideal (linear)')

    ax.set_xlabel('Number of Threads', fontsize=12)
    ax.set_ylabel('Speedup (vs 1 thread)', fontsize=12)
    ax.set_title('Strong Scaling Analysis', fontsize=14, fontweight='bold')
    ax.legend(fontsize=11)
    ax.grid(True, alpha=0.3)
    ax.set_xticks(sorted(par_df['Threads'].unique()))

    plt.tight_layout()
    output_file = output_dir / 'strong_scaling.png'
    plt.savefig(output_file, dpi=300, bbox_inches='tight')
    print(f"✓ Strong scaling saved to: {output_file}")
    plt.close()


def plot_variant_comparison(df, output_dir):
    """Plot program variant comparison"""
    # Get VC algorithm across all variants
    variants = ['base', 'contract', 'heavy', 'recursive']

    variant_data = []
    for variant in variants:
        variant_df = df[(df['Variant'] == variant) & (df['Algorithm'] == 'vc')]
        if not variant_df.empty:
            variant_data.append({
                'Variant': variant,
                'Time': variant_df['Time'].values[0]
            })

    if not variant_data:
        print("⚠️  No variant comparison data found")
        return

    variant_df = pd.DataFrame(variant_data)

    fig, ax = plt.subplots(figsize=(10, 6))

    colors = plt.cm.Set2(range(len(variant_df)))
    bars = ax.bar(variant_df['Variant'], variant_df['Time'], color=colors)

    ax.set_ylabel('Time (seconds)', fontsize=12)
    ax.set_xlabel('Program Variant', fontsize=12)
    ax.set_title('Program Variant Comparison (VC Algorithm)', fontsize=14, fontweight='bold')
    ax.grid(axis='y', alpha=0.3)

    # Add value labels
    for bar in bars:
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2., height,
                f'{height:.3f}s',
                ha='center', va='bottom', fontsize=10)

    plt.tight_layout()
    output_file = output_dir / 'variant_comparison.png'
    plt.savefig(output_file, dpi=300, bbox_inches='tight')
    print(f"✓ Variant comparison saved to: {output_file}")
    plt.close()


def generate_summary_report(df, output_dir):
    """Generate summary statistics report"""
    report_file = output_dir / 'summary_report.txt'

    with open(report_file, 'w') as f:
        f.write("=" * 80 + "\n")
        f.write("VieCut Performance Analysis Summary Report\n")
        f.write("=" * 80 + "\n\n")

        # Sequential algorithms
        seq_df = df[(df['Threads'] == 1) & (df['Variant'] == 'base')]
        seq_algos = ['ks', 'noi', 'matula', 'vc', 'pr', 'cactus']
        seq_data = seq_df[seq_df['Algorithm'].isin(seq_algos)]

        if not seq_data.empty:
            f.write("1. SEQUENTIAL ALGORITHMS\n")
            f.write("-" * 80 + "\n")
            fastest = seq_data.loc[seq_data['Time'].idxmin()]
            slowest = seq_data.loc[seq_data['Time'].idxmax()]
            f.write(f"   Fastest: {fastest['Algorithm']} ({fastest['Time']:.3f}s)\n")
            f.write(f"   Slowest: {slowest['Algorithm']} ({slowest['Time']:.3f}s)\n")
            f.write(f"   Speedup: {slowest['Time'] / fastest['Time']:.2f}x\n")
            f.write(f"   Average: {seq_data['Time'].mean():.3f}s\n\n")

        # Parallel algorithms
        par_df = df[df['Algorithm'].str.contains('par', na=False)]
        if not par_df.empty:
            f.write("2. PARALLEL PERFORMANCE\n")
            f.write("-" * 80 + "\n")

            best_speedup = par_df.loc[par_df['Speedup'].idxmax()]
            f.write(f"   Best Speedup: {best_speedup['Algorithm']} with {int(best_speedup['Threads'])} threads\n")
            f.write(f"                 {best_speedup['Speedup']:.2f}x speedup, {best_speedup['Efficiency']:.2f}% efficiency\n\n")

            # Efficiency at different thread counts
            f.write("   Average Efficiency by Thread Count:\n")
            for threads in sorted(par_df['Threads'].unique()):
                avg_eff = par_df[par_df['Threads'] == threads]['Efficiency'].mean()
                f.write(f"      {int(threads)} threads: {avg_eff:.2f}%\n")
            f.write("\n")

        # Cut value validation
        f.write("3. CORRECTNESS VALIDATION\n")
        f.write("-" * 80 + "\n")
        unique_cuts = df['Cut'].unique()
        if len(unique_cuts) == 1:
            f.write(f"   ✓ All algorithms found the same minimum cut: {unique_cuts[0]}\n\n")
        else:
            f.write(f"   ✗ WARNING: Found different cut values: {unique_cuts}\n\n")

        f.write("=" * 80 + "\n")

    print(f"✓ Summary report saved to: {report_file}")


def main():
    if len(sys.argv) < 2:
        print("Usage: python3 visualize_results.py <csv_file>")
        print("Example: python3 visualize_results.py test_results_20241224_123456.csv")
        sys.exit(1)

    csv_file = Path(sys.argv[1])

    if not csv_file.exists():
        print(f"❌ Error: File '{csv_file}' not found!")
        sys.exit(1)

    print(f"\n{'='*80}")
    print(f"VieCut Results Visualization")
    print(f"{'='*80}")
    print(f"Input file: {csv_file}")

    # Read CSV
    try:
        df = pd.read_csv(csv_file)
        print(f"✓ Loaded {len(df)} test results")
    except Exception as e:
        print(f"❌ Error reading CSV: {e}")
        sys.exit(1)

    # Create output directory
    output_dir = csv_file.parent / 'visualizations'
    output_dir.mkdir(exist_ok=True)
    print(f"✓ Output directory: {output_dir}")
    print()

    # Generate plots
    print("Generating visualizations...")
    plot_sequential_comparison(df, output_dir)
    plot_parallel_speedup(df, output_dir)
    plot_strong_scaling(df, output_dir)
    plot_variant_comparison(df, output_dir)

    # Generate summary report
    print()
    print("Generating summary report...")
    generate_summary_report(df, output_dir)

    print()
    print(f"{'='*80}")
    print(f"✓ All visualizations completed!")
    print(f"  Check the '{output_dir}' directory for results")
    print(f"{'='*80}\n")


if __name__ == '__main__':
    main()
